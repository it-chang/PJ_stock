{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6f10678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join, getmtime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "536388a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä»Šå¤©æ˜¯ï¼š æ˜ŸæœŸä¸€\n",
      "2025-07-21\n",
      "2025-07-21\n"
     ]
    }
   ],
   "source": [
    "today = datetime.today()\n",
    "weekday = today.weekday()  # 0 = Monday, 6 = Sunday\n",
    "\n",
    "# è½‰æ›æˆä¸­æ–‡æ˜ŸæœŸ\n",
    "week_map = ['æ˜ŸæœŸä¸€', 'æ˜ŸæœŸäºŒ', 'æ˜ŸæœŸä¸‰', 'æ˜ŸæœŸå››', 'æ˜ŸæœŸäº”', 'æ˜ŸæœŸå…­', 'æ˜ŸæœŸæ—¥']\n",
    "print(\"ä»Šå¤©æ˜¯ï¼š\", week_map[weekday])\n",
    "diffdays=0\n",
    "#########\n",
    "if weekday==5:   \n",
    "    diffdays=1\n",
    "if weekday==6:\n",
    "    diffdays=2\n",
    "#######\n",
    "\n",
    "####\n",
    "today=(datetime.now()-timedelta(days=diffdays)).date()\n",
    "adate=(datetime.now()-timedelta(days=diffdays)).strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "print(today)\n",
    "print(adate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf203ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base è³‡æ–™ ['2025-07-07', '2025-07-08', '2025-07-09', '2025-07-10', '2025-07-11', '2025-07-12', '2025-07-13', '2025-07-14', '2025-07-15', '2025-07-16', '2025-07-17', '2025-07-18', '2025-07-19', '2025-07-20', '2025-07-21']\n",
      "============================\n",
      "join æ–°è³‡æ–™æ—¥ 2025-07-21\n"
     ]
    }
   ],
   "source": [
    "start_month = '2023-01-01'\n",
    "start_date = datetime.strptime(start_month, \"%Y-%m-%d\").date()\n",
    "dateList = []\n",
    "current_date = start_date\n",
    "while current_date <= today:\n",
    "    dateList.append(f\"{current_date.year}-{current_date.month:02d}-{current_date.day:02d}\")\n",
    "    current_date += timedelta(days=1)\n",
    "    \n",
    "dateList=dateList[-15:]\n",
    "print('Base è³‡æ–™',dateList)\n",
    "print('============================')\n",
    "print('join æ–°è³‡æ–™æ—¥',adate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d80a520",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error----->D:\\Project\\Jupyter\\Stock\\Main\\Result\\DailyFiles\\2025-07-12.xlsx\n",
      "error----->D:\\Project\\Jupyter\\Stock\\Main\\Result\\DailyFiles\\2025-07-13.xlsx\n",
      "error----->D:\\Project\\Jupyter\\Stock\\Main\\Result\\DailyFiles\\2025-07-19.xlsx\n",
      "error----->D:\\Project\\Jupyter\\Stock\\Main\\Result\\DailyFiles\\2025-07-20.xlsx\n"
     ]
    }
   ],
   "source": [
    "new_DailyResult_path_List=[]\n",
    "new_RunRealTimeStock_path_List = [f'D:\\\\Project\\\\Jupyter\\\\Stock\\\\Main\\\\Result\\\\DailyRunRealTimeStock\\\\{adate}.xlsx']\n",
    "new_DailyResult_path_List = [ f\"D:\\Project\\Jupyter\\Stock\\Main\\Result\\DailyFiles\\\\{date}.xlsx\" for date in dateList] \n",
    "#new_RunRealTimeStock_path_List = [f'\\\\\\\\auohqeshtt02\\\\d$\\\\Production\\\\CMMM\\\\Result\\\\DailyRunRealTimeStock\\\\{adate}.xlsx']\n",
    "#new_DailyResult_path_List = [ f\"\\\\\\\\auohqeshtt02\\\\d$\\\\Production\\\\CMMM\\\\Result\\\\DailyFiles\\\\{date}.xlsx\" for date in dateList] \n",
    "\n",
    "data=StockBaseData=pd.read_csv('BaseInfo/StockBaseData.csv', converters={'å…¬å¸ä»£è™Ÿ': str})\n",
    "\n",
    "_df =  pd.DataFrame()\n",
    "for path in new_RunRealTimeStock_path_List:\n",
    "    try:\n",
    "        _df=pd.concat([pd.read_excel(path), _df])\n",
    "    except:\n",
    "        print('error----->'+path)\n",
    "    \n",
    "_df2 = pd.DataFrame()\n",
    "for path in new_DailyResult_path_List:\n",
    "    try:\n",
    "        _df2=pd.concat([pd.read_excel(path), _df2])\n",
    "    except:\n",
    "        print('error----->'+path)\n",
    "        \n",
    "df=pd.merge( _df2,_df[pd.notna(_df['now_price'])], left_on='stock_number', right_on='stock_number', how='outer')\n",
    "\n",
    "#print(_df2.dtypes)\n",
    "#print(_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa3ba135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  GetStockInfoByID(StocKID,strtype):\n",
    "    try :\n",
    "        result=data[data['å…¬å¸ä»£è™Ÿ']==StocKID]\n",
    "        if strtype=='name':\n",
    "            return result.iloc[0]['å…¬å¸ç°¡ç¨±']\n",
    "        if strtype=='category':\n",
    "            if result.iloc[0]['Type']==\"ä¸Šæ«ƒ\" :\n",
    "                return result.iloc[0]['ä¸Šæ«ƒå…¬å¸ç”¢æ¥­é¡åˆ¥']\n",
    "            else:\n",
    "                return result.iloc[0]['ä¸Šå¸‚å…¬å¸ç”¢æ¥­é¡åˆ¥']\n",
    "        if strtype=='type':\n",
    "            return result.iloc[0]['Type']\n",
    "    except :\n",
    "        print(StocKID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c5d6654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_LevelArea(row):\n",
    "    _level=float( row['level'])\n",
    "\n",
    "    if row['interval_type']=='æ­£å€é–“': \n",
    "        _level=_level*1\n",
    "\n",
    "    if row['interval_type']=='è² å€é–“':\n",
    "        _level=_level*-1\n",
    "    return _level\n",
    "\n",
    "def stock_quote(row):\n",
    "    try:\n",
    "        open_price = float(row['é–‹ç›¤åƒ¹'])\n",
    "        if open_price == 0:\n",
    "            return 0.0\n",
    "        return round(float(row['æ¼²è·Œåƒ¹å·®']) / open_price * 100, 2)\n",
    "    except (ValueError, TypeError):\n",
    "        return 0.0\n",
    "def  diff_quote(row):\n",
    "    try :\n",
    "        if float(row['é–‹ç›¤åƒ¹_y'])!=0:\n",
    "            return format((  float(row['é–‹ç›¤åƒ¹_y']) - float(row['now_price']) ) /float(row['é–‹ç›¤åƒ¹_y'])*100, '.2f')\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(row['_quote'])\n",
    "\n",
    "def trading_volume(row):\n",
    "    data=row['æˆäº¤è‚¡æ•¸']\n",
    "    try :\n",
    "         if row['Type2']=='ä¸Šå¸‚': \n",
    "                data=data/1000\n",
    "    except FileNotFoundError:\n",
    "          print(data)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a22c21",
   "metadata": {},
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ba9ae2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns in one go to avoid repeating `df.rename()`\n",
    "rename_dict = {\n",
    "    'æ—¥æœŸ_x': 'æ—¥æœŸ',\n",
    "    'now_price_x': 'now_price',\n",
    "    'change_price_x': 'change_price',\n",
    "    'change_quote_x': 'change_quote'\n",
    "}\n",
    "df.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "# Convert date columns\n",
    "date_columns = ['æ—¥æœŸ', 'highlight_date', 'highlight_enddate']\n",
    "for col in date_columns:\n",
    "    df[col] = pd.to_datetime(df[col], errors='coerce')  # å…ˆè½‰æ›æˆ datetimeï¼Œç„¡æ³•è½‰æ›çš„è¨­ç‚º NaT\n",
    "    df[col] = df[col].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Apply stock information based on 'stock_number' and add new columns\n",
    "stock_columns = ['Type0', 'Type1', 'Type2']\n",
    "stock_info_types = ['name', 'category', 'type']\n",
    "for i, col in enumerate(stock_columns):\n",
    "    df[col] = df.apply(lambda x: f\"{GetStockInfoByID(str(x['stock_number']), stock_info_types[i])}\", axis=1)\n",
    "\n",
    "df['Type'] = df['Type0'] + '-' + df['Type1'] + '-' + df['Type2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1444291b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MA5_%']=(df['æ”¶ç›¤åƒ¹']-df['MA_short'])/ abs(df['MA_short'])\n",
    "df['å‡åƒ¹_%']=(df['MA_short']-df['MA_long'])/ abs(df['MA_long'])\n",
    "df['å‡åƒ¹long_%']=(df['MA_long']-df['MA_longlong'])/ abs(df['MA_longlong'])\n",
    "df['MACD_%']=(df['MACD']-df['MACD-SL'])/ abs(df['MACD-SL'])\n",
    "df['VPC_MA_%']=(df['Volume_MA_short']-df['Volume_MA_long'])/ abs(df['Volume_MA_long'])\n",
    "\n",
    "df['MA5_%'] =( 100*df['MA5_%']).astype(float).apply(lambda x: f\"{x:.2f}\").astype(str)\n",
    "df['å‡åƒ¹_%'] = (100*df['å‡åƒ¹_%']).astype(float).apply(lambda x: f\"{x:.2f}\").astype(str)\n",
    "df['å‡åƒ¹long_%'] = (100*df['å‡åƒ¹long_%']).astype(float).apply(lambda x: f\"{x:.2f}\").astype(str)\n",
    "df['MACD_%'] = (100*df['MACD_%']).astype(float).apply(lambda x: f\"{x:.2f}\").astype(str)\n",
    "df['VPC_MA_%']=(100*df['VPC_MA_%']).astype(float).apply(lambda x: f\"{x:.2f}\").astype(str)\n",
    "\n",
    "#è™•ç†æ•¸å€¼ NA ,æµ®é»èˆ‡è½‰str\n",
    "df['change_quote'] = df['change_quote'].astype(str).str.replace(\"+\", \"\", regex=False).str.replace(\"%\", \"\", regex=False)\n",
    "df['change_quote'] = pd.to_numeric(df['change_quote'], errors='coerce').fillna('0.00').astype(str)\n",
    "df['MACD'] = df['MACD'] .astype(float).apply(lambda x: f\"{x:.2f}\").astype(str)\n",
    "df['MACD-SL'] = df['MACD-SL'].astype(float).apply(lambda x: f\"{x:.2f}\").astype(str)\n",
    "df['now_price'] = pd.to_numeric(df['now_price'], errors='coerce').fillna('0.00').astype(str)\n",
    "df['æ”¶ç›¤åƒ¹'] = pd.to_numeric(df['æ”¶ç›¤åƒ¹'], errors='coerce').fillna('0.00').astype(str)\n",
    "\n",
    "df['MA_break'] = df['MA_break'].fillna(False)\n",
    "df['MACD_golden_cross'] = df['MACD_golden_cross'].fillna(False)\n",
    "df['stock_number'] = df['stock_number'].astype(str)\n",
    "\n",
    "\n",
    "df['Volume_Oscillator'] = (\n",
    "    df['Volume_Oscillator']\n",
    "    .replace([np.inf, -np.inf], 0)  # æŠŠ inf/-inf æ›æˆ 0\n",
    "    .fillna(0)                      # æŠŠ NaN è£œ 0\n",
    "    .astype(int)                    # å®‰å…¨è½‰ int\n",
    "    .astype(str)                    # å†è½‰æˆæ–‡å­—\n",
    ")\n",
    "df['level'] = (df['level'] * 100).astype(str)\n",
    "df['now_price'] = df['now_price'].astype(str)\n",
    "\n",
    "df['æ¼²è·Œåƒ¹å·®'] = pd.to_numeric(df['æ¼²è·Œåƒ¹å·®'], errors='coerce').fillna(0)\n",
    "df['Volume_Price_Change_sum'] = df['VPC_MACD'].fillna('0').astype(float).apply(lambda x: f\"{x:.2f}\").astype(float)\n",
    "df['VPC_SIGNAL'] = df['VPC_SIGNAL'].fillna('0').astype(float).apply(lambda x: f\"{x:.2f}\").astype(float)\n",
    "df['Volume_%'] = (df['VPC_MACD'] - df['VPC_SIGNAL']) / abs(df['VPC_SIGNAL'])\n",
    "df['Volume_%'] = df['Volume_%'].round(2)\n",
    "\n",
    "# Apply custom functions for additional calculations\n",
    "df['_quote'] = df.apply(stock_quote, axis=1)\n",
    "\n",
    "df['LevelArea'] = df.apply(stock_LevelArea, axis=1)\n",
    "df['æˆäº¤è‚¡æ•¸'] = df.apply(trading_volume, axis=1)\n",
    "\n",
    "# Handle 'Typelevel' logic more efficiently\n",
    "df['Typelevel'] = df.apply(lambda x: f\"{x['Type1']}å³ä¸Š\" if x['LevelArea'] >= 50 else (\n",
    "    f\"{x['Type1']}å¹³\" if -40 <= x['LevelArea'] < 50 else f\"{x['Type1']}å³ä¸‹\"), axis=1)\n",
    "\n",
    "# Replace all '-' values with 0\n",
    "df.replace('-', 0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18653c7d",
   "metadata": {},
   "source": [
    "df[ (df['stock_number']=='1101')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6fd2531",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=df\n",
    "aa['VPC_MACD'] = pd.to_numeric(aa['VPC_MACD'], errors='coerce')\n",
    "aa['_quote'] = pd.to_numeric(aa['_quote'], errors='coerce')\n",
    "aa['now_price'] = pd.to_numeric(aa['now_price'], errors='coerce')\n",
    "aa['æ”¶ç›¤åƒ¹'] = pd.to_numeric(aa['æ”¶ç›¤åƒ¹'], errors='coerce')\n",
    "aa['æ”¶ç›¤åƒ¹'] =pd.to_numeric(aa['æ”¶ç›¤åƒ¹'], errors='coerce').apply(lambda x: f\"{x:.2f}\" if pd.notna(x) else \"0\").astype(float)\n",
    "aa['æœ€ä½åƒ¹'] =pd.to_numeric(aa['æœ€ä½åƒ¹'], errors='coerce').apply(lambda x: f\"{x:.2f}\" if pd.notna(x) else \"0\").astype(float)\n",
    "aa['æœ€é«˜åƒ¹'] =pd.to_numeric(aa['æœ€é«˜åƒ¹'], errors='coerce').apply(lambda x: f\"{x:.2f}\" if pd.notna(x) else \"0\").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "152e0c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "## å–å¾—å…¶ä»–è³‡è¨Š\n",
    "stock_info = pd.read_excel('Result/StockInfo.xlsx', engine='openpyxl')\n",
    "stock_type = pd.read_excel('Result/StockType.xlsx', engine='openpyxl')\n",
    "\n",
    "stock_info=pd.merge(left=stock_info, right=stock_type, on=\"stock_number\",how='left')\n",
    "\n",
    "# ç¡®ä¿ä¸¤ä¸ª DataFrame çš„ `stock_number` åˆ—ä¸ºå­—ç¬¦ä¸²ç±»å‹\n",
    "aa['stock_number'] = aa['stock_number'].astype(str)\n",
    "\n",
    "stock_info['stock_number'] = stock_info['stock_number'].astype(str)\n",
    "stock_info['desc'] = stock_info['desc'].fillna(\"-\")\n",
    "stock_info['æˆäº¤é‡'] = (stock_info['æˆäº¤é‡'] .str.replace(\",\", \"\"))\n",
    "stock_info['æ®–åˆ©ç‡']=stock_info['æ®–åˆ©ç‡'].str.replace(\"%\", \"\")\n",
    "stock_info['ç¸½å¸‚å€¼'] = (stock_info['ç¸½å¸‚å€¼'] .str.replace(\",\", \"\"))\n",
    "stock_info['ä¸€å¹´å…§æœ€å¤§é‡'] = (stock_info['ä¸€å¹´å…§æœ€å¤§é‡'] .str.replace(\",\", \"\"))\n",
    "stock_info['ä¸€å¹´å…§æœ€ä½é‡'] = (stock_info['ä¸€å¹´å…§æœ€ä½é‡'] .str.replace(\",\", \"\"))\n",
    "stock_info['ç‡Ÿæ¥­æ¯›åˆ©ç‡']=stock_info['ç‡Ÿæ¥­æ¯›åˆ©ç‡'].replace(\"%\", \"\")\n",
    "stock_info['ç‡Ÿæ¥­åˆ©ç›Šç‡']=stock_info['ç‡Ÿæ¥­åˆ©ç›Šç‡'].replace(\"%\", \"\")\n",
    "\n",
    "# åˆå¹¶ä¸¤ä¸ª DataFrame\n",
    "aa = pd.merge(left=aa, right=stock_info, on=\"stock_number\",how='left')\n",
    "\n",
    "aa['ç‡Ÿæ”¶æ¯”é‡'] = aa['ç‡Ÿæ”¶æ¯”é‡'].fillna(\"-\")\n",
    "aa['é‡èƒ½'] = aa['æˆäº¤è‚¡æ•¸'].astype(float)/ aa['ä¸€å¹´å…§æœ€å¤§é‡'].fillna(0).astype(int) \n",
    "aa['é‡èƒ½'] = (aa['é‡èƒ½'] *100) .apply(lambda x: f\"{x:.2f}\").astype(str)\n",
    "aa['now_price']=aa['now_price'].replace(\",\", \"\").astype(float)\n",
    "\n",
    "aa['æ¯è‚¡æ·¨å€¼(å…ƒ)'] = aa['æ¯è‚¡æ·¨å€¼(å…ƒ)'].str.strip()  # å»æ‰å‰å¾Œç©ºç™½\n",
    "aa['æ¯è‚¡æ·¨å€¼(å…ƒ)'] = aa['æ¯è‚¡æ·¨å€¼(å…ƒ)'].str.replace(\",\", \"\", regex=True).astype(float)\n",
    "aa['æ·¨å€¼å€ç‡']=(aa['now_price']/aa['æ¯è‚¡æ·¨å€¼(å…ƒ)']).astype(float).apply(lambda x: f\"{x:.2f}\")\n",
    "aa['diff_quote'] = aa.apply(diff_quote, axis=1)\n",
    "\n",
    "aa['_quote'] = pd.to_numeric(aa['_quote'], errors='coerce')\n",
    "aa['æœ¬ç›Šæ¯”'] = pd.to_numeric(aa['æœ¬ç›Šæ¯”'], errors='coerce')\n",
    "aa['diff_quote'] = pd.to_numeric(aa['diff_quote'], errors='coerce')\n",
    "aa['æˆäº¤é‡']=aa['æˆäº¤é‡'].fillna('0').astype(int).astype(str)\n",
    "\n",
    "rename_dict = {\n",
    "    'æ”¶ç›¤åƒ¹_x': 'æ”¶ç›¤åƒ¹',\n",
    "    'æœ€ä½åƒ¹_x': 'æœ€ä½åƒ¹',\n",
    "    'æœ€é«˜åƒ¹_x': 'æœ€é«˜åƒ¹',\n",
    "    'é–‹ç›¤åƒ¹_x': 'é–‹ç›¤åƒ¹'\n",
    "}\n",
    "aa.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "#åå¤šç¨‹åº¦ - åç©ºç¨‹åº¦\n",
    "#æ­£æ•¸ â†’ åå¤šï¼ˆæ”¶ç›¤åƒ¹åå‘é«˜é»ï¼‰\n",
    "#è² æ•¸ â†’ åç©ºï¼ˆæ”¶ç›¤åƒ¹åå‘ä½é»ï¼‰\n",
    "#æ¥è¿‘ 0 â†’ æ”¶ç›¤åœ¨é«˜ä½ä¹‹é–“ï¼Œç›¤æ•´æˆ–ä¸æ˜é¡¯\n",
    "\n",
    "aa['åƒ¹èƒ½'] =((aa['æ”¶ç›¤åƒ¹']-aa['æœ€ä½åƒ¹'])/aa['æœ€ä½åƒ¹'])-((aa['æœ€é«˜åƒ¹']-aa['æ”¶ç›¤åƒ¹'])/aa['æ”¶ç›¤åƒ¹']) \n",
    "aa['åƒ¹èƒ½'] = (aa['åƒ¹èƒ½']*100 ) .apply(lambda x: f\"{x:.2f}\").astype(str)\n",
    "\n",
    "aa['rt_price']  =''\n",
    "aa['rt_é‡']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f849592a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>é–‹ç›¤åƒ¹</th>\n",
       "      <th>é–‹ç›¤åƒ¹_y</th>\n",
       "      <th>now_price</th>\n",
       "      <th>diff_quote</th>\n",
       "      <th>_quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11656</th>\n",
       "      <td>124.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>125.5</td>\n",
       "      <td>5.64</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         é–‹ç›¤åƒ¹  é–‹ç›¤åƒ¹_y  now_price  diff_quote  _quote\n",
       "11656  124.0  133.0      125.5        5.64     0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa[ (aa['stock_number']=='3037') &( aa['æ—¥æœŸ']=='2025-07-10')][['é–‹ç›¤åƒ¹','é–‹ç›¤åƒ¹_y','now_price','diff_quote','_quote']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd7c7293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_js_equivalent(df: pd.DataFrame, n: int = 5) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df['æ—¥æœŸ_'] = pd.to_datetime(df['æ—¥æœŸ'])\n",
    "    def generate_textdesc(row):\n",
    "        price_desc = \"æ¼²\" if row['æ¼²è·ŒBYNå¤©Diff'] > 2 else \"è·Œ\" if row['æ¼²è·ŒBYNå¤©Diff'] < -3 else \"-\"\n",
    "        volume_desc = \"å¢\" if row['å¢ç¸®BYNå¤©Diff'] > 2 else \"ç¸®\" if row['å¢ç¸®BYNå¤©Diff'] < -10 else \"-\"\n",
    "        return f\"åƒ¹{price_desc}é‡{volume_desc}\"\n",
    "    def process_group(group):\n",
    "        group = group.sort_values('æ—¥æœŸ_').reset_index(drop=True)\n",
    "    \n",
    "        group['å¢ç¸®BYNå¤©'] = group['é‡èƒ½'].rolling(window=n).apply(lambda x: sum(x.dropna()), raw=False).fillna(0).astype(int) \n",
    "        group['å¢ç¸®BYNå¤©Diff'] = group['å¢ç¸®BYNå¤©'].rolling(window=2).apply(lambda x: sum(x.diff().dropna()), raw=False)\n",
    "        \n",
    "        group['æ¼²è·ŒBYNå¤©'] = group['_quote'].rolling(window=n).apply(lambda x: sum(x.dropna()), raw=False).fillna(0).astype(int) \n",
    "        group['æ¼²è·ŒBYNå¤©Diff'] = group['æ¼²è·ŒBYNå¤©'].rolling(window=2).apply(lambda x: sum(x.diff().dropna()), raw=False)\n",
    "            \n",
    "        group['textdesc'] = group.apply(generate_textdesc, axis=1)\n",
    "        return group\n",
    "    \n",
    "    if 'stock_number' in df.columns:\n",
    "        df = df.groupby('stock_number', group_keys=False).apply(process_group)\n",
    "    else:\n",
    "        df = process_group(df)\n",
    "\n",
    "    return df\n",
    "aa = calc_js_equivalent(aa, n=3)\n",
    "#qq=aa[ (aa['stock_number']=='6776')]\n",
    "#qq = calc_js_equivalent(qq, n=5)\n",
    "#qq[ (qq['stock_number']=='6776')][['æ—¥æœŸ','_quote','é‡èƒ½','æ¼²è·ŒBYNå¤©','å¢ç¸®BYNå¤©','æ¼²è·ŒBYNå¤©Diff','å¢ç¸®BYNå¤©Diff','textdesc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7b0835f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['æ—¥æœŸ', 'æˆäº¤è‚¡æ•¸', 'æˆäº¤é‡‘é¡', 'é–‹ç›¤åƒ¹', 'æœ€é«˜åƒ¹', 'æœ€ä½åƒ¹', 'æ”¶ç›¤åƒ¹', 'æ¼²è·Œåƒ¹å·®', 'æˆäº¤ç­†æ•¸',\n",
       "       'å¹´æœˆæ—¥', 'å‰æ—¥æ”¶ç›¤åƒ¹', 'MACD', 'MACD-SL', 'MACD_golden_cross', '%K', '%D',\n",
       "       'KD_golden_cross', 'MA_short', 'MA_long', 'MA_longlong',\n",
       "       'MA_break', 'RSI', 'RSI_rebound', 'Volume_Price_Change',\n",
       "       'Volume_MA_short', 'Volume_MA_long', 'Volume_Oscillator',\n",
       "       'VPC_MACD', 'VPC_SIGNAL', 'VPC_DIF', 'volume_threshold',\n",
       "       'Volume_Price_Change_break', 'highlight', 'highlight_date',\n",
       "       'highlight_enddate', 'macd_golden_crosses_area', 'VPC_break',\n",
       "       'VO_Positive', 'VO_Positive_Count', 'buy_points', 'Bar_Color',\n",
       "       'Full_Summary', 'å¯¦é«”é•·åº¦', 'Kæ£’å‹æ…‹', 'ä¸Šå½±', 'ä¸‹å½±', 'æ˜¨æ”¶', 'æ˜¨é–‹', 'æ˜¨é«˜', 'æ˜¨ä½',\n",
       "       'ä»Šé«˜', 'ä»Šä½', 'Kæ£’æ–¹å‘', 'Kæ£’çºŒå¼·ç¢ºèª', 'å¤šæ—¥Kæ£’å‹æ…‹', 'å¤šæ—¥Kæ£’æ–¹å‘', 'ä¸‰ç™½å…µ', 'ä¸‰éš»çƒé´‰',\n",
       "       'æ™¨æ˜Ÿ', 'æš®æ˜Ÿ', 'Market_State', 'Buy_Signal', 'Sell_Signal',\n",
       "       'Watch_Signal', 'Reversal_Signal', 'RSI_diff', 'Action_Advice',\n",
       "       'Advice_Score', 'stock_number', 'level', 'interval_type',\n",
       "       'lower_bound', 'upper_bound', 'now_price', 'change_price',\n",
       "       'change_quote', 'æ—¥æœŸ_y', 'now_price_y', 'change_price_y',\n",
       "       'change_quote_y', 'Type0', 'Type1', 'Type2', 'Type', 'MA5_%',\n",
       "       'å‡åƒ¹_%', 'å‡åƒ¹long_%', 'MACD_%', 'VPC_MA_%',\n",
       "       'Volume_Price_Change_sum', 'Volume_%', '_quote', 'LevelArea',\n",
       "       'Typelevel', 'é–‹ç›¤åƒ¹_y', 'æœ€é«˜åƒ¹_y', 'æœ€ä½åƒ¹_y', 'æ”¶ç›¤åƒ¹_y', 'æ¼²è·Œ', 'ä¸€å¹´å…§æœ€é«˜åƒ¹',\n",
       "       'ä¸€å¹´å…§æœ€ä½åƒ¹', 'æœ¬ç›Šæ¯”', 'ä¸€å¹´å…§æœ€å¤§é‡', 'ä¸€å¹´å…§æœ€ä½é‡', 'æˆäº¤é‡', 'åŒæ¥­å¹³å‡æœ¬ç›Šæ¯”', 'ä¸€å¹´ä¾†æœ€é«˜æœ¬ç›Šæ¯”',\n",
       "       'ä¸€å¹´ä¾†æœ€ä½æœ¬ç›Šæ¯”', 'ç›¤å¾Œé‡', 'æ®–åˆ©ç‡', 'ç¸½å¸‚å€¼', '85å¹´ä¾†æœ€é«˜ç¸½å¸‚å€¼', '85å¹´ä¾†æœ€ä½ç¸½å¸‚å€¼',\n",
       "       'æŠ•è³‡å ±é…¬ç‡(07/21)', 'ç²åˆ©èƒ½åŠ›(114.1Q)', 'ä»Šå¹´ä»¥ä¾†', 'æ¯è‚¡æ·¨å€¼(å…ƒ)', 'ç‡Ÿæ¥­æ¯›åˆ©ç‡', 'è²ä»–å€¼',\n",
       "       'æœ€è¿‘ä¸€é€±', 'æ¯äººç‡Ÿæ”¶(ä»Ÿå…ƒ)', 'ç‡Ÿæ¥­åˆ©ç›Šç‡', 'æ¨™æº–å·®', 'æœ€è¿‘ä¸€å€‹æœˆ', 'æ¯è‚¡ç‡Ÿæ”¶(å…ƒ)', 'ç¨…å‰æ·¨åˆ©ç‡',\n",
       "       'æœ€è¿‘äºŒå€‹æœˆ', 'è² å‚µæ¯”ä¾‹', 'è³‡ç”¢å ±é…¬ç‡', 'æœ€è¿‘ä¸‰å€‹æœˆ', 'è‚¡åƒ¹æ·¨å€¼æ¯”', 'è‚¡æ±æ¬Šç›Šå ±é…¬ç‡', 'ç‡Ÿæ”¶æ¯”é‡',\n",
       "       'desc', 'é‡èƒ½', 'æ·¨å€¼å€ç‡', 'diff_quote', 'åƒ¹èƒ½', 'rt_price', 'rt_é‡',\n",
       "       'æ—¥æœŸ_', 'å¢ç¸®BYNå¤©', 'å¢ç¸®BYNå¤©Diff', 'æ¼²è·ŒBYNå¤©', 'æ¼²è·ŒBYNå¤©Diff', 'textdesc'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### COL\n",
    "aa.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4732bab",
   "metadata": {},
   "source": [
    "### Distinct Type\n",
    "sorted(aa['Type1'].astype(str).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c6c30d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-21\n"
     ]
    }
   ],
   "source": [
    "targetday=today.strftime('%Y-%m-%d')\n",
    "print(targetday)\n",
    "#--------------------------------------------------------\n",
    "output_col=['åˆ†é¡æ¨™ç±¤',#'é€²æ¦œåˆ†é¡ç´€éŒ„',\n",
    "            'æ—¥æœŸ','stock_number','_quote' ,\n",
    "            \n",
    "            'æˆäº¤è‚¡æ•¸','rt_é‡', 'é‡èƒ½','åƒ¹èƒ½',   #'çŸ­å¢é‡',\n",
    "            'now_price', 'rt_price','diff_quote', \n",
    "            \n",
    "            'æ¼²è·ŒBYNå¤©','å¢ç¸®BYNå¤©','æ¼²è·ŒBYNå¤©Diff','å¢ç¸®BYNå¤©Diff','textdesc',\n",
    "            'ç›¤å¾Œé‡','æˆäº¤é‡',\n",
    "            \n",
    "            'MA5_%', 'å‡åƒ¹_%','å‡åƒ¹long_%' ,'MA_long','MA_longlong', # 'MA_break',\n",
    "            'MACD_%', 'MACD','MACD-SL',# 'MACD_golden_cross',\n",
    "            '%K', '%D',        \n",
    "            \n",
    "            'VPC_MA_%','VPC_break',\n",
    "            'Volume_MA_short','Volume_MA_long','Volume_Oscillator',\n",
    "            'Volume_Price_Change_sum',# 'VPC_SIGNAL', 'Volume_Price_Change_break','Volume_%',\n",
    "            'highlight_date','highlight_enddate',\n",
    "            'Type0', 'Type1', 'Type2','Full_Summary',\n",
    "            'æ·¨å€¼å€ç‡','æ®–åˆ©ç‡','æ¯è‚¡ç‡Ÿæ”¶(å…ƒ)','æœ¬ç›Šæ¯”','ç‡Ÿæ¥­æ¯›åˆ©ç‡','ç‡Ÿæ¥­åˆ©ç›Šç‡',\n",
    "            'åŒæ¥­å¹³å‡æœ¬ç›Šæ¯”','ç¸½å¸‚å€¼','ç‡Ÿæ”¶æ¯”é‡','Type','Typelevel',\n",
    "            \n",
    "            'æ¯è‚¡æ·¨å€¼(å…ƒ)','desc'\n",
    "           ]\n",
    "\n",
    "#--------------------------------------------------------\n",
    "aa['åˆ†é¡æ¨™ç±¤']=''\n",
    "aa['é€²æ¦œåˆ†é¡ç´€éŒ„']=''\n",
    "aa[output_col] = aa[output_col].fillna(\"0\")\n",
    "aa[output_col] = aa[output_col].astype(str)\n",
    "aa[output_col] = aa[output_col].replace([\"NaN\",\"nan\",\"None\", \"\"], \"0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "079ca72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['é›»å­é›¶çµ„ä»¶æ¥­å³ä¸Š', 'é›»è…¦åŠé€±é‚Šè¨­å‚™æ¥­å³ä¸Š', 'å…¶ä»–é›»å­æ¥­å³ä¸Š', 'åŠå°é«”æ¥­å³ä¸‹', 'å¡‘è† å·¥æ¥­å³ä¸‹']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################################################################################################\n",
    "analyze_ = aa.copy() \n",
    "analyze_['Volume_Price_Change_sum'] = pd.to_numeric(analyze_['Volume_Price_Change_sum'], errors='coerce')\n",
    "\n",
    "# 1. Volume_Price_Change_sum ç¸½å’Œ\n",
    "#sum_df = analyze_.groupby(['æ—¥æœŸ', 'Typelevel'])['Volume_Price_Change_sum'].sum()/10000000.reset_index()\n",
    "sum_df = (analyze_.groupby(['æ—¥æœŸ', 'Typelevel'])['Volume_Price_Change_sum'].sum() / 1000000).reset_index()\n",
    "\n",
    "# 2. å…¨éƒ¨ stock_number è¨ˆæ•¸\n",
    "count_all_df = analyze_.groupby(['æ—¥æœŸ', 'Typelevel'])['stock_number'].count().reset_index(name='count_total')\n",
    "\n",
    "# 3. _quote > 6 æ¢ä»¶ä¸‹çš„ stock_number è¨ˆæ•¸\n",
    "count_quote_df = analyze_[analyze_['_quote'] > str(6)].groupby(['æ—¥æœŸ', 'Typelevel'])['stock_number'].count().reset_index(name='count_quote_gt_6')\n",
    "\n",
    "# åˆä½µä¸‰å€‹çµæœ\n",
    "merged_df = sum_df.merge(count_all_df, on=['æ—¥æœŸ', 'Typelevel'], how='left') \\\n",
    "                  .merge(count_quote_df, on=['æ—¥æœŸ', 'Typelevel'], how='left')\n",
    "\n",
    "# è‹¥ count_quote_gt_6 æœ‰ç¼ºå€¼ï¼Œè£œ 0\n",
    "merged_df['count_quote_gt_6'] = merged_df['count_quote_gt_6'].fillna(0).astype(int)\n",
    "\n",
    "# è‹¥ count_quote_gt_6 æœ‰ç¼ºå€¼ï¼Œè£œ 0\n",
    "merged_df['count_total'] = merged_df['count_total'].fillna(0).astype(int)\n",
    "\n",
    "merged_df['quote_ratio_str'] = merged_df['count_quote_gt_6'].astype(str) + 'ã€€/ã€€' + merged_df['count_total'].astype(str)\n",
    "\n",
    "#ivot_df = \n",
    "#merged_df[merged_df['Typelevel']=='é€šä¿¡ç¶²è·¯æ¥­å³ä¸Š']\n",
    "#merged_df.pivot(index='Typelevel', columns='æ—¥æœŸ',values='count_total').to_excel( 'Result/analyze.xlsx') \n",
    "merged_df.pivot(index='Typelevel', columns='æ—¥æœŸ',values='count_quote_gt_6').to_excel( 'Result/analyze_1.xlsx') \n",
    "merged_df.pivot(index='Typelevel', columns='æ—¥æœŸ',values='Volume_Price_Change_sum').to_excel( 'Result/analyze_2.xlsx') \n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "top5_index = merged_df.pivot(index='Typelevel', columns='æ—¥æœŸ', values='Volume_Price_Change_sum')[[targetday]] \\\n",
    "                .sort_values(by=targetday, ascending=False) \\\n",
    "                .head(5) \\\n",
    "                .index\n",
    "top5_index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3282483",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################\n",
    "###ã€å¤ªé™½åœ–ã€‘ç•¶æ—¥  è¡¨ç¾å¥½ +highlight +Volume_Price_Change_break æ•´ä½µ \n",
    "\n",
    "# ========== Step 1ï¼šäº”ç¨®åˆ†æµé‚è¼¯ A ~ E ==========\n",
    "\n",
    "# A åˆ†æµï¼šå¼·å‹¢è‚¡ï¼ˆMACD å‘ä¸Šäº¤å‰ã€å‹•èƒ½è½‰å¼·ã€æ­é… highlight æˆ– VPC çªç ´ï¼‰\n",
    "cond_a = (\n",
    "    (aa['MACD-SL'] >= str(0)) &\n",
    "    (aa['MACD_%'] > str(0)) &\n",
    "    (aa['æ—¥æœŸ'] == targetday) &\n",
    "    ((aa['highlight'] == True) | (aa['Volume_Price_Change_break'] == True))\n",
    ")\n",
    "\n",
    "# B åˆ†æµï¼šåå½ˆå‹è‚¡ï¼ˆMACD å°šæœªäº¤å‰ï¼Œä½†å‹•èƒ½å·²è½‰æ­£ï¼Œå±¬æ–¼åˆæœŸåå½ˆï¼‰\n",
    "cond_b = (\n",
    "    (aa['MACD-SL'] < str(0)) &\n",
    "    (aa['MACD_%'] > str(0)) &\n",
    "    (aa['æ—¥æœŸ'] == targetday) &\n",
    "    ((aa['highlight'] == True) | (aa['Volume_Price_Change_break'] == True))\n",
    ")\n",
    "\n",
    "# C åˆ†æµï¼šå¼±å‹¢çªç ´è‚¡ï¼ˆMACD ä»ç‚ºè² ä½†æœ‰ç•°å¸¸è¡Œç‚ºï¼Œç–‘ä¼¼ä¸»åŠ›å¡ä½ï¼‰\n",
    "cond_c = (\n",
    "    (aa['MACD_%'] < str(0)) &\n",
    "    (aa['æ—¥æœŸ'] == targetday) &\n",
    "    ((aa['highlight'] == True) | (aa['Volume_Price_Change_break'] == True))\n",
    ")\n",
    "\n",
    "# D åˆ†æµï¼šå»ºè­°é—œæ³¨è‚¡ï¼ˆæ–‡å­—æ‘˜è¦ä¸­åŒ…å«ã€Œå»ºè­°é—œæ³¨è²·é»ã€ï¼‰\n",
    "cond_d = (\n",
    "    aa['stock_number'].isin(\n",
    "        aa[aa['Full_Summary'].str.contains('å»ºè­°é—œæ³¨è²·é»', na=False)]['stock_number'].drop_duplicates()\n",
    "    )\n",
    ")\n",
    "\n",
    "# E åˆ†æµï¼šå¤šé ­æ’åˆ—è‚¡ï¼ˆæ–‡å­—æ‘˜è¦ä¸­åŒ…å«ã€Œå¤šé ­æ’åˆ—ã€ï¼‰\n",
    "cond_e = (\n",
    "    aa['stock_number'].isin(\n",
    "        aa[  (aa['æ—¥æœŸ'] == targetday) &\n",
    "           aa['Full_Summary'].str.contains('å¤šé ­æ’åˆ—', na=False)]['stock_number'].drop_duplicates()\n",
    "    )\n",
    ")\n",
    "\n",
    "# ========== Step 2ï¼šæ¨™è¨˜åˆ†é¡æ¨™ç±¤ ==========\n",
    "# å»ºç«‹ã€Œåˆ†é¡æ¨™ç±¤ã€æ¬„ä½ï¼Œç”¨æ–¼å¾ŒçºŒè¼¸å‡ºåŠè¦–è¦ºåŒ–ç”¨é€”\n",
    "\n",
    "\n",
    "def add_tag(df, condition, label):\n",
    "    # åƒ…åœ¨åˆ†é¡æ¨™ç±¤ä¸­å°šæœªåŒ…å«è©²é¡åˆ¥æ™‚æ‰åŠ å…¥\n",
    "    df.loc[condition & (~df['åˆ†é¡æ¨™ç±¤'].str.contains(label, na=False)), 'åˆ†é¡æ¨™ç±¤'] += f'{label};'\n",
    "\n",
    "# åˆå§‹åŒ–æ¬„ä½\n",
    "aa['åˆ†é¡æ¨™ç±¤'] = ''\n",
    "\n",
    "# ç´¯åŠ é¡åˆ¥ï¼ˆé¿å…é‡è¤‡ï¼‰\n",
    "add_tag(aa, cond_a, 'å¼·å‹¢è‚¡')\n",
    "add_tag(aa, cond_b, 'åå½ˆå‹è‚¡')\n",
    "add_tag(aa, cond_c, 'å¼±å‹¢çªç ´è‚¡')\n",
    "add_tag(aa, cond_d, 'å»ºè­°é—œæ³¨è‚¡')\n",
    "add_tag(aa, cond_e, 'å¤šé ­æ’åˆ—è‚¡')\n",
    "\n",
    "# æ¸…é™¤å°¾ç«¯åˆ†è™Ÿ\n",
    "aa['åˆ†é¡æ¨™ç±¤'] = aa['åˆ†é¡æ¨™ç±¤'].str.strip(';')\n",
    "# ========== Step 3ï¼šä¾åˆ†é¡è¼¸å‡º A ~ E Excel ==========\n",
    "# æ¯å€‹é¡å‹å„è‡ªè¼¸å‡ºæˆä¸€ä»½å ±è¡¨\n",
    "åˆ†é¡å°æ‡‰æª”å = {\n",
    "    'å¼·å‹¢è‚¡': 'Result/checksun_a',#.xlsx',\n",
    "    'åå½ˆå‹è‚¡': 'Result/checksun_b',#.xlsx',\n",
    "    'å¼±å‹¢çªç ´è‚¡': 'Result/checksun_c',#.xlsx',\n",
    "    'å»ºè­°é—œæ³¨è‚¡': 'Result/checksun_d',#.xlsx',\n",
    "    'å¤šé ­æ’åˆ—è‚¡': 'Result/checksun_e',#.xlsx'\n",
    "}\n",
    "\n",
    "for label, filepath in åˆ†é¡å°æ‡‰æª”å.items():\n",
    "    # Step 1ï¼šæ‰¾å‡ºæ‰€æœ‰ã€Œç•¶æ—¥ç¬¦åˆè©²é¡åˆ¥ã€çš„ (è‚¡ç¥¨ä»£è™Ÿ, æ—¥æœŸ)\n",
    "    matched_rows = aa[\n",
    "        aa['åˆ†é¡æ¨™ç±¤'].str.contains(label, na=False)\n",
    "    ][['stock_number', 'æ—¥æœŸ']].drop_duplicates()\n",
    "\n",
    "    # ====== ğŸ”’ [é€²æ¦œåˆ†é¡ç´€éŒ„å¯«å…¥] æ­¤å€å¡Šå·²æ¨™è¨»ï¼Œå¦‚éœ€å•Ÿç”¨å¯è§£é™¤è¨»è§£ ======\n",
    "    \"\"\"\n",
    "    for _, row in matched_rows.iterrows():\n",
    "        stock = row['stock_number']\n",
    "        date = row['æ—¥æœŸ']\n",
    "        match_idx = aa[aa['stock_number'] == stock].index\n",
    "        for idx in match_idx:\n",
    "            entry = f\"{label}({date})\"\n",
    "            if entry not in aa.at[idx, 'é€²æ¦œåˆ†é¡ç´€éŒ„']:\n",
    "                aa.at[idx, 'é€²æ¦œåˆ†é¡ç´€éŒ„'] += entry + ';'\n",
    "    \"\"\"\n",
    "    # ======================================================\n",
    "\n",
    "    # Step 2ï¼šå¾ aa æŠŠé€™äº›è‚¡ç¥¨çš„æ‰€æœ‰æ­·å²è³‡æ–™æ’ˆå‡ºä¾†\n",
    "    matched_stocks = matched_rows['stock_number'].drop_duplicates().tolist()\n",
    "    df_filtered = aa[aa['stock_number'].isin(matched_stocks)]\n",
    "    \n",
    "    os.makedirs(filepath, exist_ok=True)\n",
    "    # Step 3ï¼šè¼¸å‡ºåˆ†é¡æª”æ¡ˆï¼ˆå®Œæ•´æ­·å²è³‡æ–™ï¼‰\n",
    "    df_filtered[output_col].drop_duplicates().sort_values(\n",
    "        by=['stock_number', 'æ—¥æœŸ'], ascending=False\n",
    "    ).to_excel(f'{filepath}/{targetday}.xlsx', index=False)\n",
    "# ========== Step 4ï¼šF åˆ†æµï¼ˆæ³•äººé—œæ³¨åº¦ _quote > 4ï¼‰==========\n",
    "# å¤šæ—¥è™•ç†ï¼Œæ¯å¤©è¼¸å‡ºä¸€ä»½ï¼Œæ”¾å…¥ Result/checksun_f è³‡æ–™å¤¾\n",
    "# ç”¨æ–¼è§€å¯Ÿæ³•äººè©•åˆ†è¼ƒé«˜çš„æ½›åŠ›è‚¡\n",
    "os.makedirs('Result/checksun_f', exist_ok=True)\n",
    "\n",
    "for _date in dateList:\n",
    "    datalist = aa[(aa['æ—¥æœŸ'] == _date) & (aa['_quote'] > str(4))]['stock_number'].drop_duplicates().tolist()\n",
    "    maskfilter = aa['stock_number'].isin(datalist)\n",
    "    filepath = f'Result/checksun_f/{_date}.xlsx'\n",
    "    aa[output_col][maskfilter].drop_duplicates().sort_values(\n",
    "        by=['stock_number', 'æ—¥æœŸ'], ascending=False\n",
    "    ).to_excel(filepath, index=False)\n",
    "\n",
    "# ========== Step 5ï¼šVPC_break åˆ†æµ ==========\n",
    "# åƒ¹é‡åŒæ­¥çªç ´ï¼šVPC_break ç‚º True\n",
    "# å°æ‡‰æŠ€è¡“å‹ä¸»åŠ›çªç ´è¡Œç‚ºï¼Œå±¬æ–¼çŸ­ç·šå¼·å‹¢è¿½è¹¤è‚¡\n",
    "os.makedirs('Result/checksun_v', exist_ok=True)\n",
    "datalist = aa[(aa['VPC_break'] == 'True')]['stock_number'].drop_duplicates().tolist()\n",
    "maskfilter = aa['stock_number'].isin(datalist)\n",
    "filepath = f'Result/checksun_v/{targetday}.xlsx'\n",
    "aa[output_col][maskfilter].drop_duplicates().sort_values(by=['stock_number', 'æ—¥æœŸ'], ascending=False).to_excel(filepath, index=False)\n",
    "\n",
    "\n",
    "# ========== Step 6ï¼šå…¶ä»–æœªåˆ†é¡è‚¡ç¥¨ ==========\n",
    "# ä¸åœ¨ Aï½E é¡åˆ¥ã€éæ³•äººé—œæ³¨ï¼ˆFï¼‰ã€ä¹Ÿä¸æ˜¯ VPC_breakï¼ˆVï¼‰\n",
    "\n",
    "# å…ˆå–å¾—æ‰€æœ‰å·²æœ‰åˆ†é¡çš„è‚¡ç¥¨ä»£è™Ÿ\n",
    "classified_stocks = set()\n",
    "\n",
    "# åŠ å…¥ A~E åˆ†é¡è‚¡ç¥¨\n",
    "for label in åˆ†é¡å°æ‡‰æª”å:\n",
    "    classified_stocks.update(\n",
    "        aa[aa['åˆ†é¡æ¨™ç±¤'].str.contains(label, na=False)]['stock_number'].drop_duplicates().tolist()\n",
    "    )\n",
    "\n",
    "# åŠ å…¥æ³•äººé—œæ³¨ F é¡\n",
    "for _date in dateList:\n",
    "    classified_stocks.update(\n",
    "        aa[(aa['æ—¥æœŸ'] == _date) & (aa['_quote'] > str(2))]['stock_number'].drop_duplicates().tolist()\n",
    "    )\n",
    "\n",
    "# åŠ å…¥ VPC_break åˆ†é¡\n",
    "classified_stocks.update(\n",
    "    aa[\n",
    "        (aa['VPC_break'] == 'True')\n",
    "    ]['stock_number'].drop_duplicates().tolist()\n",
    ")\n",
    "\n",
    "# æ‰€æœ‰è‚¡ç¥¨ - å·²åˆ†é¡çš„ = å…¶ä»–æœªåˆ†é¡\n",
    "all_stocks = aa[aa['æ—¥æœŸ'] == targetday]['stock_number'].drop_duplicates().tolist()\n",
    "unclassified_stocks = list(set(all_stocks) - classified_stocks)\n",
    "\n",
    "# ç¯©é¸è³‡æ–™ä¸¦è¼¸å‡º\n",
    "maskfilter = aa['stock_number'].isin(unclassified_stocks) & (aa['æ—¥æœŸ'] == targetday)\n",
    "filepath = f'Result/checksun_others/{targetday}.xlsx'\n",
    "os.makedirs('Result/checksun_others', exist_ok=True)\n",
    "\n",
    "aa[output_col][maskfilter].drop_duplicates().sort_values(\n",
    "    by=['stock_number', 'æ—¥æœŸ'], ascending=False\n",
    ").to_excel(filepath, index=False)\n",
    "\n",
    "###########################################################################################################\n",
    "#ã€å¤ªé™½åœ–ã€‘è‡ªå®š å–å¾—è¡¨ç¾å¥½ä¸”è³‡é‡‘æµå‘ --------------------------------------------------------------------------------------\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "os.makedirs('Result/checksun_aa', exist_ok=True)\n",
    "to_excel1 = f'Result/checksun_aa/{targetday}.xlsx'\n",
    "myList=aa[(cond_a & aa['Typelevel'].isin(top5_index.tolist()))]['stock_number'].drop_duplicates().tolist()\n",
    "maskfilter=  (aa['stock_number'].isin(myList))\n",
    "aa[output_col][maskfilter].drop_duplicates().sort_values(by=['stock_number','æ—¥æœŸ',], ascending=False).to_excel(to_excel1, index=False)\n",
    "\n",
    "###########################################################################################################\n",
    "###########################################################################################################\n",
    "#ã€å¤ªé™½åœ–ã€‘è‡ªå®š æŒæœ‰ --------------------------------------------------------------------------------------\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "to_excel='Result/checksunmy.xlsx' \n",
    "datalist=[ '1101', '1599','2062', '2301', '2349','2542','3066','4966','6789']\n",
    "maskfilter=(aa['stock_number'].isin(datalist))\n",
    "aa[output_col][maskfilter].drop_duplicates().sort_values(by=['stock_number','æ—¥æœŸ',], ascending=False).to_excel(to_excel, index=False)\n",
    "\n",
    "#ã€ã€‘è‡ªå®š (By ç°¡ç¨±)--------------------------------------------------------------------------------------\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "#to_excel1='Result/checksundangchong.xlsx'   \n",
    "#myList=['é™½æ˜','é•·æ¦®','è¯ç¶“','è¯æ˜Ÿå…‰']\n",
    "#maskfilter=(aa['Type0'].isin(myList))\n",
    "#aa[output_col][maskfilter].drop_duplicates().sort_values(by=['stock_number','æ—¥æœŸ',], ascending=False).to_excel(to_excel1, index=False)\n",
    "\n",
    "###########################################################################################################\n",
    "########################################################################################################\n",
    "\n",
    "###ã€å¤ªé™½åœ–ã€‘åˆ†é¡åˆ¥ BYæ—¥  -----------------------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------------------------------------------\n",
    "os.makedirs('Result/checksun', exist_ok=True)\n",
    "for Type1 in sorted(aa['Type1'].astype(str).unique()): \n",
    "    to_excel1='Result/checksun/'+Type1+'.xlsx'\n",
    "    datalist=aa[ (aa['Type1']==Type1)]['stock_number'].drop_duplicates().tolist()\n",
    "    maskfilter=(aa['stock_number'].isin(datalist))# & (aa['highlight']==True) \n",
    "    aa[output_col][maskfilter].drop_duplicates().sort_values(by=['stock_number','æ—¥æœŸ',], ascending=False).to_excel(to_excel1, index=False)\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "##############################################################################################\n",
    "cc=aa.copy()\n",
    "cc[output_col] = cc[output_col].astype(str)\n",
    "cc[output_col] = cc[output_col].replace([\"NaN\",\"nan\",\"None\", \"\"], \"0\")\n",
    "\n",
    "###ã€RowDataã€‘æ‰€æœ‰è‚¡ç¥¨ BYæ—¥ --------------------------------------------------------------------------------\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "os.makedirs('Result/checkall', exist_ok=True)\n",
    "for _date in dateList: \n",
    "    maskfilter=(aa['æ—¥æœŸ']==_date) \n",
    "    to_excel1='Result/checkall/'+_date+'.xlsx'\n",
    "    cc[output_col][ maskfilter].drop_duplicates().sort_values(by=['stock_number','æ—¥æœŸ',], ascending=False).to_excel(to_excel1, index=False) \n",
    "    \n",
    "###ã€RowDataã€‘è‡ªå®š æŒæœ‰---------------------------------------------------------------------------------------\n",
    "#-----------------------------------------------------------------------------------------------    \n",
    "to_excel1='Result/checkmy.xlsx'   \n",
    "myList=[ '1101', '1599','2062', '2301', '2349', '2376', '2542','3066','4966','6789']\n",
    "maskfilter= (aa['æ—¥æœŸ']==targetday) & (aa['stock_number'].isin(myList))\n",
    "cc[output_col][maskfilter].drop_duplicates().sort_values(by=['stock_number','æ—¥æœŸ',], ascending=False).to_excel(to_excel1, index=False)\n",
    "\n",
    "##################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a31b50fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JS CHECK DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5466e8",
   "metadata": {},
   "source": [
    "function getMissingElements(array1, array2) {\n",
    "    return array1.filter(element => !array2.includes(element));\n",
    "\n",
    "}\n",
    "array1=app.jsonData.map(x=>x.stock_number)\n",
    "array2=app.filteredData.map(x=>x.stock_number)\n",
    "getMissingElements(array1, array2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f42b0af",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
